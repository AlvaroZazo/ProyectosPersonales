{"cells":[{"cell_type":"markdown","metadata":{"id":"w6FtEVbFoszy"},"source":["# 08 - NLTK: Clasificación de textos con Naive Bayes\n","\n","* En este notebook vamos a ver como crear un modelo que clasifique las frases según su polaridad (Positiva o Negativa).\n","\n","\n","* Para ello tenemos 3 conjuntos de frases que son:\n","    1. **Positivas**: Conjunto de frases clasificadas con polaridad positiva\n","    2. **Negativas**: Conjunto de frases clasificadas con polaridad negativa\n","    3. **Test**: Conjunto de frases de test a predecir.\n","    \n","\n","* El framework para la clasificación de texto (y para la clasificación en general) es el siguiente:\n","\n","    - ***Entrenamiento***:\n","    \n","        1. Limpieza y ***normalización*** del texto\n","        2. ***Extracción de características***: esto consiste en crear la estructura de datos necesaria para que la utilice el algoritmo de aprendizaje a usar\n","        3. ***Algoritmo de Aprendizaje***: Dado el conjunto de características de los texto y la etiqueta (label) de los textos, el algoritmo de aprendizaje dará como resultado un **modelo**.\n","<br><br>     \n","    - ***Predicción***:\n","    \n","        1. Limpieza y ***normalización*** del texto a clasificar.\n","        2. ***Extracción de características*** del texto a clasificar. Tanto este punto 2 como el anterior (1) deben de realizarse de la misma manera que en la fase de entrenamiento.\n","        3. ***Predicción***: Dado el conjunto de características de los ***texto a predecir*** y el **modelo**, este devolverá la ***clasificación*** (o predicción) del texto.\n","        \n","        \n","* Este framework lo podemos ver en la siguiente imagen:\n","\n","<img src=\"./imgs/009_Clasificacion_framework.png\" style=\"width: 500px;\"/>\n","\n","\n","<hr>\n","\n","\n","## Ejemplo con NLTK:\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"FwchHOLfosz8","executionInfo":{"status":"ok","timestamp":1646929859888,"user_tz":-60,"elapsed":1564,"user":{"displayName":"ALVARO ALVAREZ ZAZO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13862881707039858072"}}},"outputs":[],"source":["import re\n","import nltk\n","import nltk.classify\n","from nltk.corpus import stopwords\n","\n","positive = [('I love this car', 'positive'),\n","            ('This view is amazing', 'positive'),\n","            ('I feel great this morning', 'positive'),\n","            ('I am so excited about the concert', 'positive'),\n","            ('He is my best friend', 'positive'),\n","            ('Going well', 'positive'),\n","            ('Thank you', 'positive'),\n","            ('Hope you are doing well', 'positive'),\n","            ('I am very happy', 'positive'),\n","            ('Good for you', 'positive'),\n","            ('It is all good. I know about it and I accept it.', 'positive'),\n","            ('This is really good!', 'positive'),\n","            ('Tomorrow is going to be fun.', 'positive'),\n","            ('These are great apples today.', 'positive'),\n","            ('How about them apples? Thomas is a happy boy.', 'positive'),\n","            ('I love this sandwich.', 'positive'),\n","            ('This is an amazing place!', 'positive'),\n","            ('I feel very good about these beers.', 'positive'),\n","            ('This is my best work.', 'positive'),\n","            ('What an awesome view', 'positive')]\n","\n","negative = [('I do not like this car', 'negative'),\n","            ('This view is horrible', 'negative'),\n","            ('I feel tired this morning', 'negative'),\n","            ('I am not looking forward to the concert', 'negative'),\n","            ('He is my enemy', 'negative'),\n","            ('I am a bad boy', 'negative'),\n","            ('This is not good', 'negative'),\n","            ('I am bothered by this', 'negative'),\n","            ('I am not connected with this', 'negative'),\n","            ('Sadistic creep you ass. Die.', 'negative'),\n","            ('All sorts of crazy and scary as hell.', 'negative'),\n","            ('Not his emails, no.', 'negative'),\n","            ('His father is dead. Returned obviously.', 'negative'),\n","            ('He has a bomb.', 'negative'),\n","            ('Too fast to be on foot. We cannot catch them.', 'negative'),\n","            ('I do not like this restaurant', 'negative'),\n","            ('I am tired of this stuff.', 'negative'),\n","            (\"I can't deal with this\", 'negative'),\n","            ('He is my sworn enemy!', 'negative'),\n","            ('My boss is horrible.', 'negative')]\n","\n","test = [('I feel happy this morning', 'positive'),\n","        ('Larry is my friend', 'positive'),\n","        ('I do not like that man', 'negative'),\n","        ('My house is not great', 'negative'),\n","        ('Your song is annoying', 'negative'),\n","        ('The beer was good.', 'positive'),\n","        ('I do not enjoy my job', 'negative'),\n","        (\"I feel amazing!\", 'positive'),\n","        ('Gary is a friend of mine.', 'positive'),\n","        (\"I can't believe I'm doing this.\", 'negative')]"]},{"cell_type":"markdown","metadata":{"id":"PI_uCmegos0B"},"source":["<hr>\n","\n","\n","## Normalización\n","\n","* En primer lugar vamos a pasar a normalizar las frases. Para ello realizaremos lo siguiente:\n","\n","    - Eliminamos los signos de puntuación\n","    - Eliminamos las Stop-Words\n","    - Pasamos el texto a minúsculas\n","    \n","* Nos creamos una función que realice este procesamiento para las frases dadas.\n","\n","\n","***NOTA***: *Para este ejemplo en particular se hace una normalización muy básica pero suficiente para realizar este ejemplo con caracter didáctico*."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6sR9tmUtos0C","executionInfo":{"status":"ok","timestamp":1646929773237,"user_tz":-60,"elapsed":293,"user":{"displayName":"ALVARO ALVAREZ ZAZO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13862881707039858072"}}},"outputs":[],"source":["def normalize(sentenses):\n","    \"\"\"normalizamos la lista de frases\"\"\"\n","    sen = []\n","    for (words, sentiment) in sentenses:\n","        words_filtered = []\n","        for word in words.split():\n","            word = re.sub(r'[^\\w\\s]', '', word).lower() # Eliminamos signos de puntuación y lo pasamos a minúsculas\n","            if len(word) > 2 and word not in stopwords.words(): # Filtramos stop words y las palabras con menos de 3 caracteres\n","                words_filtered.append(word)\n","        sen.append((words_filtered, sentiment))\n","    return sen"]},{"cell_type":"markdown","metadata":{"id":"h7WNIzppos0D"},"source":["<hr>\n","\n","\n","## Extracción de características\n","\n","* El algoritmo de aprendizaje (Naive Bayes) necesita una determina estructura de datos de entrada para generar el modelo. Para ello necesitamos crear:\n","\n","    - Un Diccionario (CUIDADO no es un diccionario python) con todas las palabras del corpus.\n","    \n","    - Una tupla que contenga en la primera posición un Booleano si por cada palabra del diccionario aparece o no la palabra de la frase. El segundo elemento de la tupla es la etiqueta de la frase. \n","    \n","\n","* Para ello creamos las siguientes 2 funciones:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jU6jxbWeos0E","executionInfo":{"status":"ok","timestamp":1646929845443,"user_tz":-60,"elapsed":276,"user":{"displayName":"ALVARO ALVAREZ ZAZO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13862881707039858072"}}},"outputs":[],"source":["def get_unique_words(sentenses):\n","    \"\"\"Función que devuelve una lista con todas las palabras únicas que aparecen en las frases\"\"\"\n","    all_words = []\n","    for (words, sentiment) in sentenses:\n","        all_words.extend(words)\n","    return list(set(all_words))\n","\n","def extract_features(document):\n","    \"\"\"Función que crea el conjunto de entrenamiento del clasificador\n","       1: Toma todos los documentos del corpus\n","       2: Toma todas las palabras del corpus\n","       3: Escribre (True|False) si aparece cada palabra del corpus en la frase\n","    \"\"\"\n","    document_words = set(document)\n","    features = {}\n","    for word in unique_words:\n","        features['contains(%s)' % word] = (word in document_words)\n","    return features"]},{"cell_type":"markdown","metadata":{"id":"vBCgD3uOos0F"},"source":["* A continuación pasamos a crear el conjunto de entrenamiento:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yuwqUcbCos0F","executionInfo":{"status":"error","timestamp":1646930598765,"user_tz":-60,"elapsed":393,"user":{"displayName":"ALVARO ALVAREZ ZAZO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13862881707039858072"}},"outputId":"27ebb744-d3de-4509-b64d-4ac2955b587a"},"outputs":[{"output_type":"error","ename":"LookupError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-a362e791efff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalizamos las frases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Obtenemos las palabras del corpus (diccionario del corpus)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0munique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unique_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-e9f2f3c64329>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(sentenses)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\w\\s]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Eliminamos signos de puntuación y lo pasamos a minúsculas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Filtramos stop words y las palabras con menos de 3 caracteres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mwords_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"]}],"source":["# Normalizamos las frases\n","sentenses = normalize(positive+negative)\n","\n","# Obtenemos las palabras del corpus (diccionario del corpus)\n","unique_words = get_unique_words(sentenses)\n","\n","# Construimos el conjunto de entrenamiento\n","training_set = nltk.classify.apply_features(extract_features, sentenses)\n","\n","print(training_set[0])\n","sentenses[0]"]},{"cell_type":"markdown","metadata":{"id":"WdyaRAkSos0I"},"source":["<hr>\n","\n","\n","## Algoritmo de Aprendizaje\n","\n","* Creamos un objeto de la clase NaiveBayesClassifier y llamamos al método train pasándole los datos de entrenamiento.\n","\n","\n","* De esta manera ya tenemos el modelo creado para su uso asi como información relativa al modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9GuM2Xrzos0J"},"outputs":[],"source":["classifier = nltk.NaiveBayesClassifier.train(training_set)"]},{"cell_type":"markdown","metadata":{"id":"A0-p6NdJos0J"},"source":["<hr>\n","\n","\n","## Predicción\n","\n","* Para la predicción vamos a utilizar el modelo creado para ello vamos a:\n","    1. Normalizar las frases\n","    2. Extracción de características de la frase\n","    3. Predicción\n","\n","* Veamos a continuación como hacerlo y como clasificamos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYu_PRtfos0K","outputId":"a7974949-3d75-434b-9277-a4e924a5aba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Frase: ['feel', 'happy', 'morning']\n","\tPolaridad: positive - Predicción: positive -> BIEN\n","Frase: ['larry', 'friend']\n","\tPolaridad: positive - Predicción: positive -> BIEN\n","Frase: ['like']\n","\tPolaridad: negative - Predicción: negative -> BIEN\n","Frase: ['house', 'great']\n","\tPolaridad: negative - Predicción: positive -> MAL\n","Frase: ['song', 'annoying']\n","\tPolaridad: negative - Predicción: negative -> BIEN\n","Frase: ['beer', 'good']\n","\tPolaridad: positive - Predicción: positive -> BIEN\n","Frase: ['enjoy', 'job']\n","\tPolaridad: negative - Predicción: negative -> BIEN\n","Frase: ['feel', 'amazing']\n","\tPolaridad: positive - Predicción: positive -> BIEN\n","Frase: ['gary', 'friend']\n","\tPolaridad: positive - Predicción: positive -> BIEN\n","Frase: ['cant', 'believe']\n","\tPolaridad: negative - Predicción: negative -> BIEN\n"]}],"source":["test = normalize(test)   # Normalizamos\n","for sen in test:\n","    sentense_features = extract_features(sen[0])   # Extracción de características\n","    polarity = classifier.classify(sentense_features)   # Clasificación\n","    print('Frase: ' + str(sen[0]))\n","    print('\\tPolaridad: ' + sen[1] + ' - Predicción: ' + polarity + ' -> ' + ('BIEN' if polarity==sen[1] else 'MAL'))"]},{"cell_type":"markdown","metadata":{"id":"_Aax2A9vos0L"},"source":["<hr>\n","\n","\n","# Modelo\n","\n","* Veamos a continuación algunas características del modelo:\n","\n","\n","* Podemo ver por ejemplo la probabilidad de que una frase pertenezca a una etiqueta (label):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epZoh_gPos0M","outputId":"8c602c12-33f9-419b-b327-bf050d31e83e"},"outputs":[{"name":"stdout","output_type":"stream","text":["-> P(positivo) = 0.5\n","-> P(negativo) = 0.5\n"]}],"source":["prob_positive = classifier._label_probdist.prob('positive')\n","prob_negative =  classifier._label_probdist.prob('negative')\n","print ('-> P(positivo) = ' + str(prob_positive))\n","print ('-> P(negativo) = ' + str(prob_negative))"]},{"cell_type":"markdown","metadata":{"id":"qUe9fI9Qos0N"},"source":["* Otra cosa que podemos ver es como de relevante son las palabras que se han utilizado para construir el modelo en función de la etiqueta.\n","\n","\n","* Vemos por ejemplo que si la palabra \"good\" aparece en una frase (*contains(good) = True*), esta frase tiene 3 veces más probabilidades de clasificarse como positiva que como negativa. Esta cálculo (según el código) lo hacen de la siguiente manera:\n","\n","\n","$$positi : negati = \\frac{P(good|positivo)}{P(good|negativo)}$$\n","\n","$$negati : positi = \\frac{P(good|negativo)}{P(good|positivo)}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtET_jENos0N","outputId":"bcb157d8-1429-44fc-9177-5d48fa99c21c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Most Informative Features\n","          contains(good) = True           positi : negati =      3.0 : 1.0\n","          contains(feel) = True           positi : negati =      1.7 : 1.0\n","          contains(view) = True           positi : negati =      1.7 : 1.0\n","          contains(good) = False          negati : positi =      1.2 : 1.0\n","          contains(love) = False          negati : positi =      1.1 : 1.0\n"]}],"source":["classifier.show_most_informative_features(5)"]},{"cell_type":"markdown","metadata":{"id":"3bn25jV0os0O"},"source":["* Podemos ver tambien como calcula el peso para determinar si una frase es positiva o negativa:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1bApHAfos0P","outputId":"4df37338-941f-40ed-985b-77aef8bdc8a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicción: positive\n","{'positive': -0.1526530828020789, 'negative': -3.316091331221193}\n"]}],"source":["# Ejemplo POSITIVO\n","t = \"I feel happy this morning\"\n","print ('Predicción: ' + classifier.classify(extract_features(t.split())))\n","print (classifier.prob_classify(extract_features(t.split()))._prob_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yy27Bsfzos0Q","outputId":"17f347b3-a451-4651-eff2-e3c7a492f72d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicción: negative\n","{'positive': -2.8112705203211146, 'negative': -0.22174085358772722}\n"]}],"source":["# Ejemplo NEGATIVO\n","t = \"I do not like that man\"\n","print ('Predicción: ' + classifier.classify(extract_features(t.split())))\n","print (classifier.prob_classify(extract_features(t.split()))._prob_dict)"]},{"cell_type":"markdown","metadata":{"id":"wn8MAjj1os0R"},"source":["* Por último podemos ver la probabilidad de que una frase se clasifique como positiva o negativa en función de que aparezca o no una determinada palabra:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lHTLD0Qos0R","outputId":"4b05e01d-2922-4208-b39e-cbbe7528ecc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Probabilidad de que la frase sea NEGATIVA si APARECE la palabra 'good':\n","0.07142857142857142\n","\n","Probabilidad de que la frase sea POSITIVA si APARECE la palabra 'good':\n","0.21428571428571427\n","\n","Probabilidad de que la frase sea NEGATIVA si NO APARECE la palabra 'good':\n","0.9285714285714286\n","\n","Probabilidad de que la frase sea POSITIVA si NO APARECE la palabra 'good':\n","0.7857142857142857\n"]}],"source":["print(\"Probabilidad de que la frase sea NEGATIVA si APARECE la palabra 'good':\")\n","print (classifier._feature_probdist[('negative', 'contains(good)')].prob(True))\n","\n","print(\"\\nProbabilidad de que la frase sea POSITIVA si APARECE la palabra 'good':\")\n","print (classifier._feature_probdist[('positive', 'contains(good)')].prob(True))\n","\n","print(\"\\nProbabilidad de que la frase sea NEGATIVA si NO APARECE la palabra 'good':\")\n","print (classifier._feature_probdist[('negative', 'contains(good)')].prob(False))\n","\n","print(\"\\nProbabilidad de que la frase sea POSITIVA si NO APARECE la palabra 'good':\")\n","print (classifier._feature_probdist[('positive', 'contains(good)')].prob(False))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"08_NLTK_Clasificacion_Textos_Naive_Bayes.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}